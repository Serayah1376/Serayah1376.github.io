<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Pytorch深度学习实践</title>
      <link href="/nlp/2021/09/16/pytorch-shen-du-xue-xi-shi-jian/"/>
      <url>/nlp/2021/09/16/pytorch-shen-du-xue-xi-shi-jian/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=1854709891&amp;auto=1&amp;height=66"></iframe></div><p><span class="github-emoji"><span>🎵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f3b5.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>上面的歌超好听哟~~~</p><h1 id="PyTorch深度学习实践"><a href="#PyTorch深度学习实践" class="headerlink" title="PyTorch深度学习实践"></a>PyTorch深度学习实践</h1><h2 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2><p>数据集——&gt;模型设计——&gt;训练——&gt;推理<br>评估模型就称为损失，训练就是为了将损失降到最低<br>MSE：平均平方误差<br>线性模型的一个例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">]</span>y_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token comment">#训练函数</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> x<span class="token operator">*</span>w<span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_pred<span class="token operator">=</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>y_pred<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>w_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>mse_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> w <span class="token keyword">in</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">4.1</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w='</span><span class="token punctuation">,</span>w<span class="token punctuation">)</span>    l_sum<span class="token operator">=</span><span class="token number">0</span>    <span class="token keyword">for</span> x_val<span class="token punctuation">,</span>y_val <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>x_data<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred_val<span class="token operator">=</span>forward<span class="token punctuation">(</span>x_val<span class="token punctuation">,</span>w<span class="token punctuation">)</span>        loss_val<span class="token operator">=</span>loss<span class="token punctuation">(</span>x_val<span class="token punctuation">,</span>y_val<span class="token punctuation">,</span>w<span class="token punctuation">)</span>        l_sum<span class="token operator">+=</span>loss_val        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">,</span>x_val<span class="token punctuation">,</span>y_val<span class="token punctuation">,</span>y_pred_val<span class="token punctuation">,</span>loss_val<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'MSE='</span><span class="token punctuation">,</span>l_sum<span class="token operator">/</span><span class="token number">3</span><span class="token punctuation">)</span>    w_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>w<span class="token punctuation">)</span>    mse_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>l_sum<span class="token operator">/</span><span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>w_list<span class="token punctuation">,</span>mse_list<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'w'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h2><p>鞍点：梯度为零的点<br>用到的核心公式：<br>其中w是选择的参数，α是一个每次下降的多少，后面是当前的梯度<br><img src="https://img-blog.csdnimg.cn/1dc9d8394ee042618eb747e311ee5a5e.png" alt="梯度下降算法"></p><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">]</span>y_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span>w<span class="token operator">=</span><span class="token number">1.0</span><span class="token comment">#训练函数</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> x<span class="token operator">*</span>w<span class="token comment">#损失函数</span><span class="token keyword">def</span> <span class="token function">cost</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    cost<span class="token operator">=</span><span class="token number">0.0</span>    <span class="token keyword">for</span> xs<span class="token punctuation">,</span>ys <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred<span class="token operator">=</span>forward<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>        cost<span class="token operator">+=</span><span class="token punctuation">(</span>y_pred<span class="token operator">-</span>ys<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>y_pred<span class="token operator">-</span>ys<span class="token punctuation">)</span>    <span class="token keyword">return</span> cost<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment">#用len函数取得列表的长度</span><span class="token keyword">def</span> <span class="token function">gradient</span><span class="token punctuation">(</span>xs<span class="token punctuation">,</span>ys<span class="token punctuation">)</span><span class="token punctuation">:</span>    grad<span class="token operator">=</span><span class="token number">0</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>xs<span class="token punctuation">,</span>ys<span class="token punctuation">)</span><span class="token punctuation">:</span>        grad<span class="token operator">+=</span><span class="token number">2</span><span class="token operator">*</span>x<span class="token operator">*</span><span class="token punctuation">(</span>x<span class="token operator">*</span>w<span class="token operator">-</span>y<span class="token punctuation">)</span>    <span class="token keyword">return</span> grad<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>xs<span class="token punctuation">)</span>w_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>loss_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predict(before training'</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>forward<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#进行100轮的训练</span>    cost_val<span class="token operator">=</span>cost<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    grad_val<span class="token operator">=</span>gradient<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    w<span class="token operator">-=</span><span class="token number">0.01</span><span class="token operator">*</span>grad_val    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch:'</span><span class="token punctuation">,</span>epoch<span class="token punctuation">,</span><span class="token string">'w='</span><span class="token punctuation">,</span>w<span class="token punctuation">,</span><span class="token string">'loss='</span><span class="token punctuation">,</span>cost_val<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predict(after training)'</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>forward<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>w_list<span class="token punctuation">,</span>loss_list<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'w'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token comment">#数据集</span>x_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">]</span>y_data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span>w<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#权重 张量 张量计算的时候系统会构建计算图，要占内存</span>w<span class="token punctuation">.</span>require_grad<span class="token operator">=</span><span class="token boolean">True</span> <span class="token comment"># 需要计算梯度，必须要设定</span><span class="token comment">#直接用张量 构建计算图</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> x<span class="token operator">*</span>w  <span class="token comment">#返回的也是一个张量</span><span class="token comment">#损失函数</span><span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    y_pred<span class="token operator">=</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>y_pred<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predict(before training):'</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>forward<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>x_data<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span><span class="token punctuation">:</span>        l<span class="token operator">=</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token comment">#计算损失函数4</span>        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#反向传播计算梯度  并清除计算图</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\tgrad:'</span><span class="token punctuation">,</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment">#更新权重值</span>        w<span class="token punctuation">.</span>data<span class="token operator">=</span>w<span class="token punctuation">.</span>data<span class="token operator">-</span><span class="token number">0.01</span><span class="token operator">*</span>w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data  <span class="token comment">#将值取出来计算，避免生成计算图</span>        w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'progress:'</span><span class="token punctuation">,</span>epoch<span class="token punctuation">,</span>l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'predict(after training)'</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>forward<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="用PyTorch实现线性回归"><a href="#用PyTorch实现线性回归" class="headerlink" title="用PyTorch实现线性回归"></a>用PyTorch实现线性回归</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token comment">#将数据初始化为张量</span>x_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">LinearModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred<span class="token operator">=</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> y_pred    model<span class="token operator">=</span>LinearModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 模型</span><span class="token comment">#构造损失函数和优化器</span>criterion<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment">#损失函数</span>optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token comment">#优化器</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y_pred<span class="token operator">=</span>model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>    loss<span class="token operator">=</span>criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#反馈之前将之前的梯度清空</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#反馈</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 更新权重</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#Test Model</span>x_test<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_test<span class="token operator">=</span>model<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y_pred='</span><span class="token punctuation">,</span>y_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="逻辑斯蒂回归（用于分类）"><a href="#逻辑斯蒂回归（用于分类）" class="headerlink" title="逻辑斯蒂回归（用于分类）"></a>逻辑斯蒂回归（用于分类）</h2><p>要找一个函数，将原来的输出对应到规定的范围内，比如[0，1]，即饱和函数<br>饱和函数中最有代表性的时逻辑斯蒂函数（西格玛）<br>损失函数也要有相应的变化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token comment">#第一步：准备数据</span>x_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 分为三个类别</span><span class="token comment">#第二步：设计模型</span><span class="token keyword">class</span> <span class="token class-name">LogisticRegressionModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred<span class="token operator">=</span>F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#添加逻辑斯蒂函数</span>        <span class="token keyword">return</span> y_predmodel<span class="token operator">=</span>LogisticRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 模型</span><span class="token comment">#第三步：构造损失函数和优化器</span>criterion<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment">#损失函数</span>optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token comment">#优化器</span><span class="token comment">#第四步：训练</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y_pred<span class="token operator">=</span>model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span> <span class="token comment">#估计值</span>    loss<span class="token operator">=</span>criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>  <span class="token comment">#损失值</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#反馈之前将之前的梯度清空</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#反馈</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 更新权重</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#Test Model</span>x_test<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_test<span class="token operator">=</span>model<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y_pred='</span><span class="token punctuation">,</span>y_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="处理多维特征输入"><a href="#处理多维特征输入" class="headerlink" title="处理多维特征输入"></a>处理多维特征输入</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment">#第一步 准本数据</span>xy<span class="token operator">=</span>np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'diabetes.csv.gz'</span><span class="token punctuation">,</span>delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token comment">#分隔符是逗号</span>x_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#如果-1不加中括号的话，出来的是一个向量</span><span class="token comment">#第二步：设计相关模型</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment">#梯度下降</span>        self<span class="token punctuation">.</span>linear1<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear2<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear3<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#非线性函数  没有参数</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 前向传播函数</span>        x<span class="token operator">=</span>self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token operator">=</span>self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token operator">=</span>self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel<span class="token operator">=</span>Model<span class="token comment">#第三步：优化和损失函数</span>criterion<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token comment">#第四步：训练</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment">#前馈</span>    y_pred<span class="token operator">=</span>model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>    loss<span class="token operator">=</span>criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment">#反馈</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment">#更新</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>激活函数的作用：加入非线性因素，解决线性模型不能解决的问题；如果不用激活函数，在这种情况下每一层输出都是上层都是上层输入的线性函数。容易验证，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这种情况就是最原始的感知机了。因此引入非线性函数作为激活函数，这样深层神经网络就有意义了。</p><h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><p>MNIST手写数据集分类</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token comment">#用于构建数据集</span><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token comment">#激活函数relu()</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token comment">#优化器</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment">#数据集的准备</span><span class="token comment">#神经网络希望输入的数据尽可能的小，尽量在0到1之间</span>batch_size<span class="token operator">=</span><span class="token number">64</span>transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#变换维度，由单通道变为多通道</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#均值和标准差  切换到0,1分布</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span>train_dataset<span class="token operator">=</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/minist'</span><span class="token punctuation">,</span>                            train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                            download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                            transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>train_loader<span class="token operator">=</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>                        shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>test_dataset<span class="token operator">=</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/minist'</span><span class="token punctuation">,</span>                            train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                            download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                            transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>test_loader<span class="token operator">=</span>DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span>                       shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                       batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span><span class="token comment">#设计模型</span><span class="token comment">#全连接神经网络输入的样本要求是1阶的向量</span><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l4<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l5<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token operator">=</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">784</span><span class="token punctuation">)</span>        x<span class="token operator">=</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token operator">=</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token operator">=</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token operator">=</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token operator">=</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l5<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel<span class="token operator">=</span>Net<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment">#损失函数和优化器</span>criterion<span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#交叉熵损失函数</span>optimizer<span class="token operator">=</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token comment">#训练</span><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss<span class="token operator">=</span><span class="token number">0.0</span>    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span>data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">,</span>target<span class="token operator">=</span>data        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment">#前向传播</span>        outputs<span class="token operator">=</span>model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        <span class="token comment">#计算损失值</span>        loss<span class="token operator">=</span>criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>target<span class="token punctuation">)</span>        <span class="token comment">#后向传播</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment">#更新</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> batch_idx<span class="token operator">%</span><span class="token number">300</span><span class="token operator">==</span><span class="token number">299</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d,%5d]loss"%.3f'</span><span class="token operator">%</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>batch_idx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>running_loss<span class="token operator">/</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            running_loss<span class="token operator">=</span><span class="token number">0.0</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct<span class="token operator">=</span><span class="token number">0</span>    total<span class="token operator">=</span><span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#不需要梯度</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            images<span class="token punctuation">,</span>labels<span class="token operator">=</span>data            outputs<span class="token operator">=</span>model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            _<span class="token punctuation">,</span>predicted<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#取出每一行最大值的下标</span>            total<span class="token operator">+=</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            correct<span class="token operator">+=</span><span class="token punctuation">(</span>predicted<span class="token operator">==</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#获得猜对的数量</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'猜对的比率是：%d %%'</span><span class="token operator">%</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>correct<span class="token operator">/</span>total<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> __name__<span class="token operator">==</span><span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>        test<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> nlp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>First</title>
      <link href="/uncategorized/2021/09/16/first/"/>
      <url>/uncategorized/2021/09/16/first/</url>
      
        <content type="html"><![CDATA[<p><del>菜得不知所措</del></p><div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=1499527753&amp;auto=1&amp;height=66"></iframe></div>]]></content>
      
      
      
        <tags>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/uncategorized/2021/09/16/hello-world/"/>
      <url>/uncategorized/2021/09/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>  <div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=1854709891&amp;auto=1&amp;height=66"></iframe></div>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
